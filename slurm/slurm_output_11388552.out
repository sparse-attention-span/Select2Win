2025-04-25 18:12:22.615913: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-25 18:12:22.708809: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1745597542.752229  159150 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1745597542.762926  159150 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1745597542.831726  159150 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1745597542.831784  159150 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1745597542.831790  159150 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1745597542.831795  159150 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-04-25 18:12:22.839627: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: fragmential (fragmential-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /gpfs/home5/scur2588/team_git/erwin/experiments/wandb/run-20250425_181233-k0r2pmwr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run erwin_shapenet
wandb: ‚≠êÔ∏è View project at https://wandb.ai/fragmential-university-of-amsterdam/ballformer
wandb: üöÄ View run at https://wandb.ai/fragmential-university-of-amsterdam/ballformer/runs/k0r2pmwr
using LucidRains

    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 Traceback (most recent call last):
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/train_shapenet.py", line 146, in <module>
    fit(config, model, optimizer, scheduler, train_loader, valid_loader, test_loader, 110, 160)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/training.py", line 127, in fit
    stat_dict = train_step(model, batch, optimizer, scheduler)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/training.py", line 59, in train_step
    stat_dict = model.training_step(batch)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/experiments/wrappers/shapenet.py", line 46, in training_step
    return self.step(batch, "train")
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/experiments/wrappers/shapenet.py", line 40, in step
    pred = self(**batch).squeeze(-1)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/experiments/wrappers/shapenet.py", line 31, in forward
    return self.pred_head(self.main_model(node_features, node_positions, **kwargs))
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/models/erwin.py", line 560, in forward
    node = layer(node)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/models/erwin.py", line 410, in forward
    node.x = blk(node.x[node.tree_idx_rot], node.pos[node.tree_idx_rot])[tree_idx_rot_inv]
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/models/erwin.py", line 368, in forward
    x = x + self.BMSA(self.norm1(x), pos)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/models/erwin.py", line 352, in forward
    x = self.sparse_attn(x.unsqueeze(0)).squeeze(0)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/models/native_sparse_attention.py", line 486, in forward
    fv = fv.gather(3, selected_block_indices)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 1024.00 MiB. GPU 0 has a total capacity of 39.50 GiB of which 978.12 MiB is free. Including non-PyTorch memory, this process has 38.53 GiB memory in use. Of the allocated memory 37.93 GiB is allocated by PyTorch, and 117.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33merwin_shapenet[0m at: [34mhttps://wandb.ai/fragmential-university-of-amsterdam/ballformer/runs/k0r2pmwr[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250425_181233-k0r2pmwr/logs[0m

JOB STATISTICS
==============
Job ID: 11388552
Cluster: snellius
User/Group: scur2588/scur2588
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:29
CPU Efficiency: 4.74% of 00:10:12 core-walltime
Job Wall-clock time: 00:00:34
Memory Utilized: 1.64 MB
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
