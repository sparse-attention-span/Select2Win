2025-04-25 19:43:50.834716: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-04-25 19:43:50.984061: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1745603031.042682 2540343 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1745603031.058907 2540343 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1745603031.159681 2540343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1745603031.159741 2540343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1745603031.159747 2540343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1745603031.159753 2540343 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-04-25 19:43:51.167729: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: fragmential (fragmential-university-of-amsterdam) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.9
wandb: Run data is saved locally in /gpfs/home5/scur2588/team_git/erwin/experiments/wandb/run-20250425_194357-zyo28iez
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run erwin_shapenet
wandb: ‚≠êÔ∏è View project at https://wandb.ai/fragmential-university-of-amsterdam/ballformer
wandb: üöÄ View run at https://wandb.ai/fragmential-university-of-amsterdam/ballformer/runs/zyo28iez
using LucidRains
/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/networkx/utils/backends.py:135: RuntimeWarning: networkx backend defined more than once: nx-loopback
  backends.update(_get_backends("networkx.backends"))

    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    bottleneck
Erwin transformer blocks:
0 1 2 3 4 5 
    decoder 0
Erwin transformer blocks:
0 1 2 3 4 5 
    encoder 0
Erwin transformer blocks:
0 Traceback (most recent call last):
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/output_graph.py", line 1446, in _call_user_compiler
    compiled_fn = compiler_fn(gm, self.example_inputs())
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/repro/after_dynamo.py", line 129, in __call__
    compiled_gm = compiler_fn(gm, example_inputs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/__init__.py", line 2235, in __call__
    return compile_fx(model_, inputs_, config_patches=self.config)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/compile_fx.py", line 1521, in compile_fx
    return aot_autograd(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/backends/common.py", line 72, in __call__
    cg = aot_module_simplified(gm, example_inputs, **self.kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 1071, in aot_module_simplified
    compiled_fn = dispatch_and_compile()
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 1056, in dispatch_and_compile
    compiled_fn, _ = create_aot_dispatcher_function(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 522, in create_aot_dispatcher_function
    return _create_aot_dispatcher_function(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_functorch/aot_autograd.py", line 759, in _create_aot_dispatcher_function
    compiled_fn, fw_metadata = compiler_fn(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py", line 179, in aot_dispatch_base
    compiled_fw = compiler(fw_module, updated_flat_args)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/compile_fx.py", line 1350, in fw_compiler_base
    return _fw_compiler_base(model, example_inputs, is_inference)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/compile_fx.py", line 1421, in _fw_compiler_base
    return inner_compile(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/compile_fx.py", line 475, in compile_fx_inner
    return wrap_compiler_debug(_compile_fx_inner, compiler_name="inductor")(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/repro/after_aot.py", line 85, in debug_wrapper
    inner_compiled_fn = compiler_fn(gm, example_inputs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/compile_fx.py", line 661, in _compile_fx_inner
    compiled_graph = FxGraphCache.load(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/codecache.py", line 1370, in load
    compiled_graph = compile_fx_fn(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/compile_fx.py", line 570, in codegen_and_compile
    compiled_graph = fx_codegen_and_compile(gm, example_inputs, **fx_kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/compile_fx.py", line 878, in fx_codegen_and_compile
    compiled_fn = graph.compile_to_fn()
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/graph.py", line 1913, in compile_to_fn
    return self.compile_to_module().call
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/graph.py", line 1839, in compile_to_module
    return self._compile_to_module()
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/graph.py", line 1867, in _compile_to_module
    mod = PyCodeCache.load_by_key_path(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/codecache.py", line 2876, in load_by_key_path
    mod = _reload_python_module(key, path)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/runtime/compile_tasks.py", line 45, in _reload_python_module
    exec(code, mod.__dict__, mod.__dict__)
  File "/scratch-local/scur2588.11390353/torchinductor_scur2588/eq/ceq6c2yuihqleatf7hj4xveyfstgttjaoqg6i4hznbagl6zl43sz.py", line 481, in <module>
    async_compile.wait(globals())
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/async_compile.py", line 276, in wait
    scope[key] = result.result()
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/codecache.py", line 3341, in result
    result = self.future.result()
  File "/usr/lib64/python3.9/concurrent/futures/_base.py", line 446, in result
    return self.__get_result()
  File "/usr/lib64/python3.9/concurrent/futures/_base.py", line 391, in __get_result
    raise self._exception
torch._inductor.compile_worker.subproc_pool.SubprocException: An exception occurred in a subprocess:

triton.compiler.errors.CompilationError: at 62:44:
    if CHECK_BLOCK_BOUNDARY:
        # Mask out the elements that are out of the KV_LEN for non divisible seqlen.
        post_mod_scores = tl.where(offs_n < KV_LEN, post_mod_scores, float("-inf"))

    if not IS_FULL_BLOCKS:
        tmp0 = tl.full([1], 32, tl.int32)
        tmp1 = tl.where(((m) < 0) != (tmp0 < 0), tl.where((m) % tmp0 != 0, (m) // tmp0 - 1, (m) // tmp0), (m) // tmp0)
        tmp2 = tl.where(((n) < 0) != (tmp0 < 0), tl.where((n) % tmp0 != 0, (n) // tmp0 - 1, (n) // tmp0), (n) // tmp0)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 1, tl.int32)
        tmp5 = tl.where(((off_h) < 0) != (tmp4 < 0), tl.where((off_h) % tmp4 != 0, (off_h) // tmp4 - 1, (off_h) // tmp4), (off_h) // tmp4)
        tmp6 = tmp3 | tl.load(in_ptr8 + (m)*s7 + s6*s7*tmp5 + tmp2)
                                            ^
NameError('s7 is not defined')

The above exception was the direct cause of the following exception:

triton.compiler.errors.CompilationError: at 57:28:
                acc, l_i, m_i,
                # Offsets
                off_z, off_h, offs_m, offs_n,
                MATMUL_PRECISION, RCP_LN2,
                IS_FULL_BLOCKS,
            )
        else:
            # Benchmark shows even we applied mod & mask to each block for non divisible seqlen,
            # it's on par or slightly faster than only applying to the last block in fwd.
            # However, we choose different strategy for bwd, where we only apply mod & mask
            # to the last block because it's faster a lot.
            acc, l_i, m_i = forward_block_mn(
                            ^

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 270, in do_job
    result = job()
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
    load_kernel().precompile(warm_cache_only=True)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 244, in precompile
    compiled_binary, launcher = self._precompile_config(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 428, in _precompile_config
    triton.compile(*compile_args, **compile_kwargs),
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/triton/compiler/compiler.py", line 276, in compile
    module = src.make_ir(options, codegen_fns, context)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/triton/compiler/compiler.py", line 113, in make_ir
    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns)
triton.compiler.errors.CompilationError: at 148:20:
    )
    V_block_ptr = tl.make_block_ptr(
        base=V,
        shape=(KV_LEN, V_HEAD_DIM),
        strides=(stride_vn, stride_vk),
        offsets=(kv_start, 0),
        block_shape=(BLOCK_N, V_HEAD_DIM),
        order=(1, 0)
    )
    offs_n = kv_start + tl.arange(0, BLOCK_N)

    acc, l_i, m_i = forward_inner(
                    ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/train_shapenet.py", line 146, in <module>
    fit(config, model, optimizer, scheduler, train_loader, valid_loader, test_loader, 110, 160)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/training.py", line 152, in fit
    val_stats = validate(model, val_loader, config)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/training.py", line 78, in validate
    stat_dict = model.validation_step(batch)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/experiments/wrappers/shapenet.py", line 50, in validation_step
    return self.step(batch, "val")
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/experiments/wrappers/shapenet.py", line 40, in step
    pred = self(**batch).squeeze(-1)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/experiments/wrappers/shapenet.py", line 31, in forward
    return self.pred_head(self.main_model(node_features, node_positions, **kwargs))
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/models/erwin.py", line 572, in forward
    node = layer(node)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/models/erwin.py", line 433, in forward
    node.x = blk(node.x, node.pos)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/models/erwin.py", line 389, in forward
    x = x + self.BMSA(self.norm1(x), pos)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/models/erwin.py", line 370, in forward
    x = self.sparse_attn(x.unsqueeze(0), sliding_window_flex_mask, fine_selection_flex_mask).squeeze(0)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/experiments/../../erwin/models/native_sparse_attention.py", line 450, in forward
    fine_attn_out = flex_attention(fq, fk, fv, block_mask = fine_block_mask, enable_gqa = True)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/eval_frame.py", line 465, in _fn
    return fn(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 1269, in __call__
    return self._torchdynamo_orig_callable(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 1064, in __call__
    result = self._inner_convert(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 526, in __call__
    return _compile(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 924, in _compile
    guarded_code = compile_inner(code, one_graph, hooks, transform)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 666, in compile_inner
    return _compile_inner(code, one_graph, hooks, transform)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_utils_internal.py", line 87, in wrapper_function
    return function(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 699, in _compile_inner
    out_code = transform_code_object(code, transform)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/bytecode_transformation.py", line 1322, in transform_code_object
    transformations(instructions, code_options)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 219, in _fn
    return fn(*args, **kwargs)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/convert_frame.py", line 634, in transform
    tracer.run()
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/symbolic_convert.py", line 2796, in run
    super().run()
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/symbolic_convert.py", line 983, in run
    while self.step():
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/symbolic_convert.py", line 895, in step
    self.dispatch_table[inst.opcode](self, inst)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/symbolic_convert.py", line 2987, in RETURN_VALUE
    self._return(inst)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/symbolic_convert.py", line 2972, in _return
    self.output.compile_subgraph(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/output_graph.py", line 1117, in compile_subgraph
    self.compile_and_call_fx_graph(tx, list(reversed(stack_values)), root)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/output_graph.py", line 1369, in compile_and_call_fx_graph
    compiled_fn = self.call_user_compiler(gm)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/output_graph.py", line 1416, in call_user_compiler
    return self._call_user_compiler(gm)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_dynamo/output_graph.py", line 1465, in _call_user_compiler
    raise BackendCompilerFailed(self.compiler_fn, e) from e
torch._dynamo.exc.BackendCompilerFailed: backend='inductor' raised:
SubprocException: An exception occurred in a subprocess:

triton.compiler.errors.CompilationError: at 62:44:
    if CHECK_BLOCK_BOUNDARY:
        # Mask out the elements that are out of the KV_LEN for non divisible seqlen.
        post_mod_scores = tl.where(offs_n < KV_LEN, post_mod_scores, float("-inf"))

    if not IS_FULL_BLOCKS:
        tmp0 = tl.full([1], 32, tl.int32)
        tmp1 = tl.where(((m) < 0) != (tmp0 < 0), tl.where((m) % tmp0 != 0, (m) // tmp0 - 1, (m) // tmp0), (m) // tmp0)
        tmp2 = tl.where(((n) < 0) != (tmp0 < 0), tl.where((n) % tmp0 != 0, (n) // tmp0 - 1, (n) // tmp0), (n) // tmp0)
        tmp3 = tmp1 == tmp2
        tmp4 = tl.full([1], 1, tl.int32)
        tmp5 = tl.where(((off_h) < 0) != (tmp4 < 0), tl.where((off_h) % tmp4 != 0, (off_h) // tmp4 - 1, (off_h) // tmp4), (off_h) // tmp4)
        tmp6 = tmp3 | tl.load(in_ptr8 + (m)*s7 + s6*s7*tmp5 + tmp2)
                                            ^
NameError('s7 is not defined')

The above exception was the direct cause of the following exception:

triton.compiler.errors.CompilationError: at 57:28:
                acc, l_i, m_i,
                # Offsets
                off_z, off_h, offs_m, offs_n,
                MATMUL_PRECISION, RCP_LN2,
                IS_FULL_BLOCKS,
            )
        else:
            # Benchmark shows even we applied mod & mask to each block for non divisible seqlen,
            # it's on par or slightly faster than only applying to the last block in fwd.
            # However, we choose different strategy for bwd, where we only apply mod & mask
            # to the last block because it's faster a lot.
            acc, l_i, m_i = forward_block_mn(
                            ^

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/compile_worker/subproc_pool.py", line 270, in do_job
    result = job()
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/runtime/compile_tasks.py", line 68, in _worker_compile_triton
    load_kernel().precompile(warm_cache_only=True)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 244, in precompile
    compiled_binary, launcher = self._precompile_config(
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/torch/_inductor/runtime/triton_heuristics.py", line 428, in _precompile_config
    triton.compile(*compile_args, **compile_kwargs),
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/triton/compiler/compiler.py", line 276, in compile
    module = src.make_ir(options, codegen_fns, context)
  File "/gpfs/home5/scur2588/team_git/erwin/erwin/lib64/python3.9/site-packages/triton/compiler/compiler.py", line 113, in make_ir
    return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns)
triton.compiler.errors.CompilationError: at 148:20:
    )
    V_block_ptr = tl.make_block_ptr(
        base=V,
        shape=(KV_LEN, V_HEAD_DIM),
        strides=(stride_vn, stride_vk),
        offsets=(kv_start, 0),
        block_shape=(BLOCK_N, V_HEAD_DIM),
        order=(1, 0)
    )
    offs_n = kv_start + tl.arange(0, BLOCK_N)

    acc, l_i, m_i = forward_inner(
                    ^


Set TORCH_LOGS="+dynamo" and TORCHDYNAMO_VERBOSE=1 for more information


You can suppress this exception and fall back to eager by setting:
    import torch._dynamo
    torch._dynamo.config.suppress_errors = True

[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33merwin_shapenet[0m at: [34mhttps://wandb.ai/fragmential-university-of-amsterdam/ballformer/runs/zyo28iez[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250425_194357-zyo28iez/logs[0m

JOB STATISTICS
==============
Job ID: 11390353
Cluster: snellius
User/Group: scur2588/scur2588
State: RUNNING
Nodes: 1
Cores per node: 18
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 00:33:18 core-walltime
Job Wall-clock time: 00:01:51
Memory Utilized: 0.00 MB
Memory Efficiency: 0.00% of 120.00 GB (120.00 GB/node)
WARNING: Efficiency statistics can only be obtained after the job has ended as seff tool is based on the accounting database data.
